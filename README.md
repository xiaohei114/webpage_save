# webpage_save
本项目基于 https://github.com/ryanker/dream_downloads

## 这个项目是做什么的
希望能把平时看到的一些文章，以html的方式保存下来，类似于网页快照。保存网页有很多种方式，以html保存，绝对是最好的方式。

因为这种方案可以最大程度保留网页原本的东西，比如网页里面的视频、音频和链接之类的。

随着时间的流逝，比如5年，10年，甚至更久，html保存的网页仍然可以还原出网页原本的样子，就好像第一次看到那个网页的模样。这种能力是其他保存方案不具备的。

我尝试过不少方法和插件，都是各有各的缺点，始终没有满足我的需求，那就干脆自己做一个。

## 为什么想要做这个项目
本质上是对各大互联网服务商的不信任。
1. 资源和谐

    游览文章的时候，发现这篇文章不错，果断添加到收藏夹，结果过段时间再看，已经无法访问了。

2. 互联网公司自身的不确定性

    - 从移动互联网兴起到如今2023年，这中间不知道倒下了多少互联网公司，也不知道现在存活的公司会不会在未来某天倒下。
    - 疫情这3年，很多公司都开始裁员和砍掉一些业务线，也许被砍的业务线就有文章或者视频之类的。

3. 作者自身的不确定性

    互联网创作兴起以来，涌现了很多优秀的创作者，但是大部分创作者都没做起来，他们心灰意冷后可能会删掉自己的文章。

从NAS的火热，也印证了这种不信任的情绪是普遍存在的，有很大一部分人需要完全自主可控的存储，数据存储在网盘，说不定哪天就没了。

## 工作原理简述
### 背景
前面说到很多保存的插件都无法让我满意，其核心就在于在现代网页设计中，很多文件的请求会放到js里面来做，比如这个js文件依赖了其他js文件。

插件不会执行下载的js文件，也不会对js文件进行分析，自然也就无法替换请求链接，导致这部分代码被游览器执行后，就会执行原来的请求。

如果以10年为尺度，可能原有的域名和接口都已经换掉了，会导致这部分文件请求失败。
### 思路
我想到两种解决方案。
1. 用一个完全由我控制的游览器来请求，这样不仅可以获取到所有文件，也可以对dom树进行分析。不过这种方案太难了，需要自己实现一个游览器。
2. 使用一个代理，所有的请求都通过代理，这样代理可以获取到所有的请求。再对下载的文件进行分析，把链接替换掉。

好在有大佬已经想出了更好的方案，就是dream_downloads。

使用游览器插件，很好的结合两种方案的优点，同时又避免了项目过于复杂，在功能性和复杂度之间达到了一个平衡。
